### 1. Contexte et enjeux du projet

#### 1.1 Contexte sanitaire et besoin de pr√©diction

Depuis la pand√©mie de COVID-19, la capacit√© √† anticiper l‚Äô√©volution d‚Äôune crise sanitaire s‚Äôest impos√©e comme un enjeu strat√©gique majeur pour les institutions de sant√© publique. Qu‚Äôil s‚Äôagisse d‚Äôallocations de ressources hospitali√®res, de campagnes de vaccination ou de mesures pr√©ventives, les acteurs publics doivent pouvoir s‚Äôappuyer sur des outils de pr√©vision fiables, transparents et accessibles.

Dans ce contexte, les donn√©es ouvertes (Open Data) ont jou√© un r√¥le crucial, mais restent souvent sous-exploit√©es en raison de leur complexit√© ou de leur h√©t√©rog√©n√©it√©. La valorisation de ces donn√©es via des mod√®les pr√©dictifs peut apporter une r√©ponse concr√®te, √† condition de combiner rigueur technique, transparence des r√©sultats et facilit√© de d√©ploiement.

#### 1.2 Objectifs p√©dagogiques et techniques du projet

Ce projet s‚Äôinscrit dans le cadre du module MSPR TPRE502, dans une logique de mise en ≈ìuvre compl√®te de la cha√Æne de valeur d‚Äôun projet IA‚ÄØ: depuis la collecte et la pr√©paration des donn√©es jusqu‚Äô√† la mise √† disposition d‚Äôun service pr√©dictif via une API.

L‚Äôobjectif √©tait double :

- **Construire une plateforme de pr√©diction multi-cibles √©pid√©miologiques**, capable de pr√©dire plusieurs indicateurs (nouveaux cas, d√©c√®s, r√©cup√©rations, etc.) en fonction de la g√©olocalisation et du temps.
- **D√©ployer une solution modulaire, conteneuris√©e et document√©e**, permettant une int√©gration rapide dans un syst√®me d‚Äôinformation de sant√© publique ou dans un outil de data visualisation.

L‚Äôensemble du projet a √©t√© men√© de mani√®re autonome, dans une logique DevOps et orient√©e utilisateur final, avec une attention particuli√®re port√©e √† la tra√ßabilit√© des r√©sultats, √† l‚Äôautomatisation des traitements, et √† la simplicit√© d‚Äôutilisation.

#### 1.3 Positionnement dans la cha√Æne de valeur Data / IA

Ce projet se positionne sur l‚Äôensemble des √©tapes du cycle de vie d‚Äôun produit Data :

- **Collecte** : extraction des donn√©es COVID et MPOX depuis une base PostgreSQL int√©grant des sources Open Data,
- **Transformation** : mod√©lisation s√©mantique avec DBT et structuration √©toile orient√©e analytique,
- **Entra√Ænement IA** : pr√©diction automatique avec AutoGluon en multi-cibles,
- **D√©ploiement** : exposition des pr√©dictions via une API REST document√©e avec FastAPI,
- **Exploitation** : visualisation via une interface frontend en React, avec int√©gration directe de l‚ÄôAPI.

Ce projet m‚Äôa permis de mobiliser √† la fois mes comp√©tences en traitement de donn√©es, en Machine Learning, en d√©veloppement backend et en architecture logicielle. Il s‚Äôint√®gre parfaitement dans mon parcours de D√©veloppeur IA & Data Science, en coh√©rence avec les attendus du titre RNCP 36581.

### 2. Cahier des charges et exigences fonctionnelles

#### 2.1 Enjeux fonctionnels

Le projet vise √† r√©pondre √† un besoin fondamental‚ÄØ: disposer d‚Äôune **plateforme simple et accessible permettant de pr√©dire des indicateurs √©pid√©miologiques** √† partir de donn√©es contextuelles (date, pays, population, etc.).

Les utilisateurs cibles sont‚ÄØ:

- des analystes de la sant√© publique souhaitant anticiper les √©volutions d‚Äôune pand√©mie,
- des d√©veloppeurs souhaitant int√©grer les pr√©dictions √† une plateforme existante,
- des d√©cideurs ayant besoin d‚Äôindicateurs synth√©tiques et pr√©dictifs.

L‚Äôobjectif est donc de proposer un syst√®me :

- **fiable**, bas√© sur des mod√®les de Machine Learning entra√Æn√©s automatiquement sur donn√©es v√©rifi√©es,
- **modulaire**, chaque cible de pr√©diction (nouveaux cas, d√©c√®s, r√©cup√©rations, etc.) disposant de son propre mod√®le,
- **accessible**, via une API REST simple et un frontend √©pur√©,
- **automatis√©**, avec g√©n√©ration dynamique des jeux de donn√©es et mise √† jour facile des mod√®les.

#### 2.2 Fonctionnalit√©s attendues

Le cahier des charges a √©t√© d√©fini autour des fonctionnalit√©s suivantes :

##### üîç Collecte et traitement des donn√©es

- Collecte de donn√©es depuis une base PostgreSQL.
- Utilisation de DBT pour la structuration des donn√©es en trois couches‚ÄØ: bronze, silver, gold.
- Nettoyage, transformation, enrichissement (moyennes mobiles, diff√©rences J/J-7, etc.).

##### üß† Entra√Ænement et gestion des mod√®les

- Entra√Ænement automatique des mod√®les avec AutoGluon pour chaque cible d√©finie.
- Optimisation par stacking multi-niveaux et √©valuation RMSE/MAE/R¬≤.
- Stockage des scores par groupe (pays, continent, ann√©e) dans des fichiers CSV versionn√©s.

##### üì¶ Mise √† disposition via API

- Cr√©ation d‚Äôune API REST sous FastAPI permettant :

  - de pr√©dire une cible en fonction de donn√©es d‚Äôentr√©e,
  - d‚Äôenregistrer la pr√©diction en base (table `predicted_pandemic_stats`),
  - de v√©rifier les mod√®les disponibles via la route `/models/available`.

##### üíª Interface utilisateur

- Mise en place d‚Äôun frontend React + Vite + Tailwind,
- Composants dynamiques (formulaire, affichage des pr√©dictions),
- Responsive design compatible desktop et mobile.

#### 2.3 Contraintes techniques

- D√©ploiement conteneuris√© avec Docker et Docker Compose,
- Respect des normes de s√©curit√© (isolation des services, gestion des variables d‚Äôenvironnement),
- Compatibilit√© avec PostgreSQL pour lecture et √©criture des donn√©es,
- Temps d'entra√Ænement limit√© √† 600 secondes par cible pour ma√Ætriser la charge machine.

#### 2.4 Contraintes organisationnelles

- Travail r√©alis√© dans le cadre d‚Äôun sprint p√©dagogique avec rendu final au **22 juillet 2025**,
- Collaboration en autonomie, avec gestion du backlog sur Trello,
- Suivi des avancements via un diagramme de Gantt produit sur Instagantt,
- Livraison compl√®te attendue sous forme de d√©p√¥t Git + rapport document√© + soutenance orale.

## 3. Architecture technique et choix technologiques

### 3.1 Vue d‚Äôensemble de l‚Äôarchitecture

L‚Äôarchitecture technique du projet a √©t√© pens√©e selon un mod√®le **modulaire, conteneuris√© et √©volutif**, reposant sur les grands principes du d√©veloppement moderne : s√©paration des responsabilit√©s, scalabilit√© et automatisation.

Elle s‚Äôarticule autour de 3 couches principales :

1. **Traitement des donn√©es** (ETL + mod√©lisation via DBT)
2. **Machine Learning** (entra√Ænement automatique des mod√®les avec AutoGluon)
3. **Exposition des r√©sultats** (API FastAPI + interface utilisateur React)

L‚Äôensemble est orchestr√© via Docker, garantissant la reproductibilit√©, la compatibilit√© entre environnements, et la facilit√© de d√©ploiement.

### 3.2 Choix des technologies

#### üß± Backend API ‚Äì FastAPI

- **Motivation** : Rapidit√© de d√©veloppement, support natif d‚ÄôOpenAPI, int√©gration facile avec Pydantic pour la validation des donn√©es.
- **Usage** : Exposition de routes REST pour la pr√©diction, la consultation des mod√®les disponibles et l‚Äôinsertion des r√©sultats en base PostgreSQL.

#### ü§ñ Machine Learning ‚Äì AutoGluon

- **Motivation** : Plateforme AutoML puissante, permettant l‚Äôautomatisation compl√®te de l‚Äôentra√Ænement de mod√®les.
- **Avantages** :

  - Support multi-mod√®les (LightGBM, CatBoost, FastAI, NeuralNetTorch, etc.),
  - Stacking automatique sur plusieurs niveaux,
  - Optimisation int√©gr√©e sur des m√©triques de r√©gression (RMSE, MAE, R¬≤),
  - D√©finition d‚Äôune limite de temps par cible (600 secondes) pour √©quilibrer performance et co√ªt.

- **R√©sultat** : Un mod√®le distinct par indicateur √©pid√©miologique, stock√© dans un r√©pertoire versionn√© (`/models/`), avec score par pays, ann√©e et continent.

#### üóÉÔ∏è Base de donn√©es ‚Äì PostgreSQL

- Stockage des donn√©es brutes et retrait√©es (mod√®le en √©toile avec table de faits et dimensions),
- Stockage des pr√©dictions effectu√©es par l‚ÄôAPI.

#### üîÑ DBT (Data Build Tool)

- **Motivation** : Structuration robuste des donn√©es en 3 couches :

  - **Bronze** : injection des donn√©es brutes COVID-19 et MPOX,
  - **Silver** : enrichissement g√©ographique et temporel,
  - **Gold** : table de faits pr√™te √† l‚Äôusage pour le Machine Learning.

- **Avantages** : documentation automatique, versionning des transformations, contr√¥le qualit√© int√©gr√©.

#### üíª Frontend ‚Äì React + Vite + Tailwind

- **Motivation** : Stack moderne, rapide √† mettre en place, r√©active et ergonomique.
- **Composants cl√©s** :

  - Formulaire d‚Äôentr√©e pour g√©n√©rer des pr√©dictions √† partir de donn√©es manuelles,
  - Affichage conditionnel des r√©sultats,
  - Ic√¥nes via Lucide React,
  - Graphiques via la librairie **Recharts**, permettant une int√©gration directe dans React sans surcharge inutile.

#### üê≥ Orchestration ‚Äì Docker & Docker Compose

- Conteneurisation des 4 services : `postgres`, `api`, `trainer`, `frontend`,
- R√©seau interne (`backend`, `frontend`) pour isolation,
- Montage du dossier partag√© `/models` pour que l‚ÄôAPI acc√®de aux mod√®les g√©n√©r√©s √† chaud par l‚Äôentra√Æneur.

### 3.3 Sch√©ma d‚Äôarchitecture

[Schema d l'architeture a a r√©cup√©rr du dossier word] ()

## 4. M√©thodologie de travail et organisation

### 4.1 Approche projet

Ce projet a √©t√© men√© selon une approche **agile**, combinant planification initiale, it√©rations courtes, livraisons interm√©diaires et ajustements progressifs. Le but √©tait de favoriser la mont√©e en comp√©tence tout en produisant un livrable concret, utile et r√©utilisable.

Nous avons adopt√© les principes suivants :

- **D√©coupage modulaire** : chaque brique technique (ETL, ML, API, Frontend) a √©t√© d√©velopp√©e ind√©pendamment mais de mani√®re coh√©rente avec les autres.
- **Tests manuels fr√©quents** : notamment sur l‚ÄôAPI, les donn√©es d‚Äôentra√Ænement, les scores AutoGluon et les pr√©dictions finales.
- **Documentation progressive** : int√©gr√©e dans les scripts DBT, les readme de chaque dossier, et synth√©tis√©e dans le livrable final.

### 4.2 Organisation et outils

#### üõ†Ô∏è Outils utilis√©s

- **Trello** pour la gestion des t√¢ches et le suivi d‚Äôavancement,
- **Git** et **GitHub** pour le versionnement,
- **Docker Compose** pour la coh√©rence entre les environnements,
- **Notion** pour la documentation compl√©mentaire,
- **Metabase** pour la visualisation m√©tier en parall√®le du projet IA.

#### üìÜ Planification

Le projet a officiellement d√©but√© en **f√©vrier 2025** avec une premi√®re phase de cadrage fonctionnel et de prise en main des sources de donn√©es.

Un **diagramme de Gantt**, r√©alis√© via Instagantt, a permis de d√©finir les jalons suivants :

| √âtape principale                     | P√©riode approximative |
| ------------------------------------ | --------------------- |
| Analyse et cadrage                   | F√©v. 2025             |
| Mise en place du mod√®le de donn√©es   | Mars 2025             |
| D√©veloppement des mod√®les DBT        | Avril 2025            |
| Entra√Ænement des mod√®les IA          | Mai 2025              |
| D√©veloppement de l‚ÄôAPI & du Frontend | Juin 2025             |
| Finalisation, tests et rendu         | Juillet 2025          |

### 4.3 R√©partition des t√¢ches

Le projet a √©t√© con√ßu comme une d√©monstration compl√®te de mes comp√©tences en d√©veloppement IA & Data, avec une implication sur l‚Äôensemble des couches techniques :

- **Traitement de la donn√©e** (DBT, PostgreSQL) ‚Äì 30 %
- **Machine Learning** (AutoGluon, scripts Python) ‚Äì 40 %
- **API & Frontend** ‚Äì 20 %
- **Documentation & coordination projet** ‚Äì 10 %

Ce d√©coupage a permis une mont√©e en autonomie progressive, avec un rythme soutenu jusqu‚Äô√† la livraison finale.

## 5. R√©sultats obtenus et √©valuation

### 5.1 R√©alisation fonctionnelle

Le projet a abouti √† une **plateforme compl√®te de pr√©diction √©pid√©miologique**, fonctionnelle et d√©ployable localement, compos√©e des √©l√©ments suivants :

- üìä **Un pipeline de traitement de donn√©es robuste** via DBT, avec des mod√®les bronze, argent et une table de faits quotidienne,
- üß† **Un moteur de Machine Learning automatique** entra√Æn√© sur plusieurs cibles avec AutoGluon, stock√© dans une arborescence `models/`,
- üåê **Une API FastAPI** exposant les pr√©dictions par cible et la consultation des mod√®les disponibles,
- üñ•Ô∏è **Une interface frontend React** avec formulaire et graphiques, connect√©e dynamiquement √† l‚ÄôAPI.

Chaque brique a √©t√© test√©e individuellement puis int√©gr√©e dans un environnement coh√©rent avec Docker Compose, garantissant un fonctionnement bout-en-bout.

### 5.2 Performances des mod√®les

Les mod√®les AutoGluon ont √©t√© entra√Æn√©s sur sept indicateurs cl√©s, incluant `new_cases`, `new_deaths`, `active_cases`, etc. Pour chaque cible, un pipeline AutoGluon a s√©lectionn√© automatiquement les meilleurs mod√®les (LightGBM, CatBoost, NeuralNetTorch, etc.) et optimis√© le score via stacking.

Un temps maximum d‚Äôentra√Ænement de 600 secondes par cible a √©t√© impos√© pour garantir un bon compromis entre performance et temps de calcul.

Les performances moyennes observ√©es (sur jeu de test) pour les mod√®les les plus stables :

| Cible          | RMSE (¬±) | R¬≤    | Mod√®le dominant     |
| -------------- | -------- | ----- | ------------------- |
| `new_cases`    | ‚âà 12.4   | 0.78  | LightGBM + CatBoost |
| `new_deaths`   | ‚âà 0.49   | -8.43 | Mod√®le non stable   |
| `active_cases` | ‚âà 34.7   | 0.69  | Ensemble weighted   |

NB : Certaines cibles instables comme `new_recovered` n‚Äôont pas pu √™tre mod√©lis√©es efficacement, ce qui a √©t√© anticip√© et g√©r√© par des contr√¥les de donn√©es avant l‚Äôentra√Ænement.

### 5.3 √âvaluation de la solution

#### ‚úÖ Points forts :

- **Automatisation avanc√©e** de bout en bout (DBT ‚Üí ML ‚Üí API),
- **Architecture modulaire et maintenable** (chaque composant isol√©),
- **Qualit√© du scoring** pour les cibles pertinentes,
- **Documentation compl√®te** pour la reprise du projet.

#### üîÑ Points de vigilance :

- Certaines **cibles ont peu de donn√©es fiables** ‚Üí am√©lioration possible via enrichissement ou ing√©nierie de features.
- **Pas encore de tests automatis√©s unitaires** (notamment c√¥t√© frontend), mais les tests manuels ont couvert les cas d‚Äôusage principaux.

5. R√©sultats obtenus et √©valuation
   5.1 Choix du framework : AutoGluon

Le projet n√©cessitait une solution d'apprentissage automatique capable de s'adapter √† plusieurs indicateurs cibles, sans multiplier la complexit√© algorithmique. AutoGluon a √©t√© retenu comme framework principal pour l‚Äôentra√Ænement des mod√®les en raison de ses atouts majeurs :

Automatisation du pipeline de machine learning : AutoGluon prend en charge l‚Äôingestion des donn√©es, le pr√©traitement, la s√©lection de mod√®les, la validation crois√©e, l‚Äôoptimisation d‚Äôhyperparam√®tres et l‚Äôassemblage final.
Stacking multi-niveaux : AutoGluon utilise une strat√©gie d‚Äôempilement (stacking) de mod√®les sur plusieurs couches (L1, L2‚Ä¶), permettant de combiner intelligemment plusieurs algorithmes comme LightGBM, CatBoost, XGBoost, NeuralNetTorch, KNN, etc.
Adaptabilit√© aux ressources : Un temps d‚Äôentra√Ænement maximal de 600 secondes a √©t√© impos√© pour chaque cible, assurant un bon √©quilibre entre performance pr√©dictive et co√ªt computationnel.
√âvaluation int√©gr√©e : Le framework permet un calcul direct de plusieurs m√©triques cl√©s : RMSE, MAE, R¬≤, et Pearson, facilitant la comparaison entre cibles.
5.2 Fonctionnement des mod√®les AutoGluon

Pour chaque indicateur cible (ex. : new_cases, new_deaths, active_cases, etc.), un mod√®le ind√©pendant est entra√Æn√© √† partir de donn√©es pr√©trait√©es (via DBT). Chaque mod√®le suit une proc√©dure stricte :

Pr√©paration du dataset :
Nettoyage des valeurs manquantes,
Ajout de features temporelles (jour, semaine, ann√©e),
Cr√©ation de moyennes mobiles sur 7 jours et deltas J-J7 pour capturer les tendances.
Split temporel :
70 % des donn√©es pour l'entra√Ænement,
15 % pour la validation,
15 % pour le test,
Une logique de fallback est int√©gr√©e si un des jeux est vide, en √©largissant dynamiquement l‚Äô√©chantillon.
S√©lection automatique de mod√®les de base :
AutoGluon essaie une centaine de configurations incluant : LightGBM (et LightGBMXT), CatBoost, XGBoost, KNN, Random Forest, Extra Trees, r√©seaux de neurones torch et FastAI.
Chaque mod√®le est entra√Æn√© et √©valu√© individuellement, puis les meilleurs sont combin√©s via un WeightedEnsemble_L2.
√âvaluation et scoring :
√Ä l‚Äôissue de l‚Äôentra√Ænement, chaque mod√®le est √©valu√© sur le jeu de test via les m√©triques pr√©cit√©es.
Les pr√©dictions sont sauvegard√©es et des scores par pays et par ann√©e sont √©galement produits sous forme de fichiers scores_by_group.csv.
Persistance des mod√®les :
Chaque mod√®le est sauvegard√© dans un dossier models/{target}/ accessible par l‚ÄôAPI FastAPI.
Une API d√©di√©e permet ensuite de charger dynamiquement le bon mod√®le et de produire des pr√©dictions en ligne √† partir de nouvelles donn√©es.
5.3 Interpr√©tation des r√©sultats

L'√©valuation des mod√®les a montr√© des performances contrast√©es selon les cibles. Les indicateurs de type new_cases ou new_deaths pr√©sentent une certaine stabilit√© gr√¢ce aux signaux temporels ajout√©s, tandis que new_recovered ou cases_per_million montrent davantage de variabilit√©, en lien avec les disparit√©s g√©ographiques et les biais de d√©claration.

Les scores n√©gatifs de R¬≤ observ√©s sur certaines cibles indiquent un fort d√©salignement entre les pr√©visions et les donn√©es r√©elles, ce qui a conduit √† des actions correctives : nettoyage plus strict, enrichissement de features, ou exclusion de cibles trop bruit√©es.

5.4 Bilan sur l‚ÄôIA et mes comp√©tences mobilis√©es

Ce projet m‚Äôa permis d‚Äôexplorer concr√®tement la mise en ≈ìuvre compl√®te d‚Äôun pipeline de machine learning en production :

Pr√©paration et ing√©nierie des features avanc√©e : int√©gration de signaux temporels, moyennes mobiles, cat√©gorisation g√©ographique.
Entra√Ænement multi-cibles automatis√© : gestion de mod√®les ind√©pendants, avec monitoring de la qualit√©.
Utilisation de mod√®les en ligne : int√©gration dans une API scalable et connect√©e √† une base PostgreSQL pour tracer les pr√©dictions.
√âvaluation fine : s√©lection de m√©triques pertinentes pour la r√©gression, et enregistrement structur√© des r√©sultats.
Capacit√© √† it√©rer rapidement pour corriger les erreurs (ex. : cibles trop bruit√©es, validation vide).
La robustesse d‚ÄôAutoGluon a √©t√© un levier important, mais c‚Äôest la ma√Ætrise de son param√©trage, de la gestion des donn√©es et de l‚Äôexploitation API qui ont permis d‚Äôen tirer le plein potentiel.
