# üìÑ Page de garde

**Nom et pr√©nom** : Tim Moyence  
**√âcole** : EPSI Bordeaux  
**Entreprise** : Projet personnel & missions freelance  
**Titre de la certification** : D√©veloppeur en Intelligence Artificielle et Data Science  
**Promotion** : 2024-2025  
**Responsable de formation** : [√Ä compl√©ter selon EPSI local]  
**Logos √† ins√©rer** : EPSI + Identit√© visuelle projet ou entreprise concern√©e

---

## üìö Sommaire

_G√©n√©r√© automatiquement selon les parties du dossier._

---

## üìù Introduction

Durant mon parcours en formation √† EPSI Bordeaux et mes projets men√©s en autonomie, lors d'une pr√©c√©dente exp√©rience en stage chez Geev, j‚Äôai d√©velopp√© une expertise progressive dans les domaines de la Data Science, du Machine Learning et de l‚Äôing√©nierie logicielle appliqu√©e √† l‚Äôintelligence artificielle.

Ce dossier professionnel vise √† d√©montrer la diversit√© des comp√©tences acquises √† travers plusieurs projets concrets :

- Une plateforme pr√©dictive √©pid√©miologique alliant mod√©lisation, API, visualisation et architecture cloud.
- Un assistant intelligent d√©di√© √† la m√©diation culturelle mus√©ale.
- Un POC de mod√©ration automatis√©e d‚Äôimages bas√© sur des capacit√©s multi-modales d‚ÄôIA g√©n√©rative.

√Ä travers ces exp√©riences, j‚Äôai consolid√© ma ma√Ætrise des outils modernes de d√©veloppement (FastAPI, AutoGluon, dbt, Metabase, Azure, LangChain, GPT, etc.), et appris √† structurer des solutions robustes et explicables, tout en respectant les enjeux √©thiques et les contraintes de mise en production.

Apr√®s quelques ann√©es de recherche de sens et de r√©orientation (une bac g√©n√©ral, suivis d'un CAP en restauration, d'une ann√©e de fac de biologie) j'ai d√©but√© une carri√®re dans le secteur du commerce, o√π j'ai travaill√©e dans un premier temps en tant que vendeur chez Leroy merlin, puis en tant que responsable de rayon chez Decathlon. Ces exp√©riences m'ont permis de d√©velopper une forte culture client, un sens de l'organisation et une capacit√© √† travailler en √©quipe et a manger celle ci.

Suite a un voyage dans les √Æles, j'ai pris conscience que je ne voulais plus continuer dans le secteur du commerce, mais chercher un metier qui me permettrait de sortir d'une zone de ocnfort et √©galement de pouvoir travailler de mani√®re autonome quelque soit l'endroit o√π je me trouve. L'envie d'apprendre et de decouvrir les dessous du num√©rique et la mani√®re dont les outils, site, applicaitons etc.. sont construitent c'est ainsi que j'ai d√©cid√© de me r√©orienter vers le secteur du developpement. Apr√®s un bootcam de 6 mois avec l'ecole O'clock j'ai pu optenir un titre professionnel de d√©veloppeur web et web mobile, ce qui m'a permis de d√©couvrir les bases du web avec Javascript. J'ai ensuite entrepris 8 mois d'approfondissement de comp√©tences en travaillant sur des projet personnels et en freelance, ce qui m'a permis d'acqu√©rir un peu plus d'experience sur les outils et les technologies du secteur.

Aujourd'hui je reste passionn√©e par l'apprentissage des technologies num√©riques, l‚Äôimpact de l‚Äôintelligence artificielle dans notre soci√©t√©, j‚Äôai donc entrepris de finaliser ma reconversion en r√©alisation ce bachelor aupr√®s de l'espi (ecole conjointe avec l'idrac ou j'ai fait mes trois premi√®re ann√©e de formation dans le commerce).
J‚Äôai ainsi pu d√©velopper une approche pragmatique et orient√©e r√©sultats, en int√©grant les enjeux de l‚Äôaccessibilit√©, de l‚Äô√©thique et de la responsabilit√© dans mes projets. Mon objectif est de contribuer √† des solutions innovantes qui r√©pondent aux besoins r√©els des utilisateurs tout en respectant les valeurs humaines et soci√©tales.

Aujourd‚Äôhui, je m‚Äôinscris dans une dynamique d‚Äôinnovation alliant IA, accessibilit√© et √©thique, avec l‚Äôambition de concevoir des outils intelligents, responsables et utiles pour la soci√©t√©. Mon profil hybride, √† la crois√©e des soft skills manag√©riales et des expertises techniques, me permet de comprendre les enjeux strat√©giques tout en livrant des impl√©mentations concr√®tes.

Mon projet professionnel s'articule autour de plusieurs axes. Le premier est un depart pour le Canada en octobre 2025. Pays dans lequel j'aimerais a partir du debut d'ann√©e 2026 avoir trouv√© une entreprise me permettant de travailler en tant que manager ou lead dev. En effet, par mon cursus scolaire et mes experience en management, j'aimerais faire valoir mes comp√©tences manag√©riales et techniques dans un poste de lead dev ou manager technique. Je suis convaincu que mon profil hybride, alliant comp√©tences techniques et manag√©riales, me permettra de contribuer efficacement √† des projets innovants et √† fort impact.

Le deuxi√®me axe est de continuer a developper un POC pour l'assistant intelligent d√©di√© √† la m√©diation culturelle mus√©ale. En effet ce projet me tient particuli√®rement √† c≈ìur car il un r√©√©l besoin que je vie au quotidien et qui au fils des discusssion que j'ai pu avoir en pr√©sentant le proejt un besoin dont je ne suis pas le seul a partager. Je souhaite d√©velopper cet assistant intelligent pour am√©liorer l'exp√©rience des visiteurs dans les mus√©es, en leur offrant un acc√®s facilit√© aux informations et aux ressources culturelles, rendant ainsi les mus√©es accessible a tous.

---

## I. Environnement professionnel

### 1. Pr√©sentation de l‚Äôentreprise

J'ai √©t√© lors de cette ann√©e acceuillis pour mon alternance par l'entreprise Beecoming, entreprise cr√©√© en 2019 par deux fr√®re et un amis d'enfance. Bas√© en charente maritime et sp√©cialis√© dans le d√©veloppement de solutions num√©riques tourn√©e vers l'industrie par le pass√© et les contacts des dirigeants L'entreprise compte une vingtaine de collaborateurs et se concentre sur la cr√©ation d'applications web et mobiles.

**[Donner un peu plus de contexte sur l'entreprise, ses valeurs, sa mission et son positionnement dans le secteur de l'IA et de la Data Science. Mentionner les projets r√©cents ou les innovations notables.]**

---

### 2. Beecoming et mon r√¥le

J'ai integr√©e beecoming en tant que d√©veloppeur fullstack en alternance, avec pour mission de travailler sur un projet de gestion de chais. J'ai pu dans le cadre de cette alternance avoir le role de developpeur web, de developpeur mobile avec Ionic et de gestonnaire de projet. J'ai √©t√© en charge du role de product manager sur ce projet et lead dev pour une equipe de 3 personnes (moi compris). J'ai pu ainsi exp√©rimenter la gestion de projet agile, la mise en place de sprints et la coordination d'√©quipe dans un contexte ou l'efficience etait primordiale.

J'ai √©galement pu travailler sur la mise en place de l'architecture technique du projet, la gestion des versions. L'application developp√© l'a √©t√© en C# pour la partie front et back end web, et en Ionic pour la partie mobile. J'ai √©galement pu travailler sur la mise en place de l'API REST et la gestion des donn√©es avec une base de donn√©es postgres.

Des missions de developpement applicatif a base d'intelligence artificielle etait pr√©vu, mais n'ont pas pu etre r√©alis√©es dans le cadre de cette alternance. Le manque de temps li√©e a mes diff√©renytes missions, et la rapidit√© d'avancement du projet n'a pas permis de les int√©grer a ce jour. Celle reste pr√©vu pour la V2 du projet, cependant nous sommes encore sur la V1 qui doit sortir en septembre apr√®s un ans de developpement.

J'ai par ailleurs eu l'opportunit√© de travailler sur des projets dans le cadre des mes etudes avec l'EPSI mais √©galement avant ma formation avec un POC r√©alis√© chez Geev pendant 2 mois de stage entre avril et juin 2024.
Cela m'a permit de mettre en pratique la gestion de call API avec diff√©rentes IA par le biais de Langchain permettant le plug and play de diff√©rentes IA, ainsi que la gestion de la data avec des outils comme dbt et Metabase.
J'ai √©galement pu travailler sur la mise en place des pr√©mices d'un assistant intelligent d√©di√© √† la m√©diation culturelle mus√©ale, projet qui me tient particuli√®rement √† c≈ìur.

### 3. Le projet de gestion de chais

Le projet de gestion de chais est un projet d'application, web et mobile, destin√©e √† optimiser la gestion des chais pour les personnes travaillant dans le cognass√©. Il permet de suivre gr√¢ce a trois modules :

- Vendanges
- Vinification
- Gestion de chais

De g√©rer les diff√©rentes √©tapes de la production du cognac, de la r√©colte des raisins √† la mise en bouteille. L'application permet √©galement de suivre les stocks, g√©rer les intrants, les num√©ros de DAE, les num√©ros de lots d'intrant, le suivis de la vinificaiton par l'ajout d'analyses et prise de mesures a des lots, g√©rer les stocks de vin. L'objectif final est a l'avenir de prendre en compte les donn√©es de la vigne a la mise en bouteille et de permettre une tra√ßabilit√© compl√®te du processus de production avec gestion de saisis douani√®re.

L'application est d√©velopp√©e en C# utilissant le framework ASP.NET Core Blazor pour la partie web (front et back), l'avantage de cette technologie et ce framework est la mise en place d'un environnement de communication unifi√© ou aucune route n'est necessaire pour la mise en place d'une communication front et back. En effet, blazor aspire cr√©er un websocket qui permet une connection instantann√©e et plus fluide au sein de l'application.

---

#### Architecture FRONT et BACK

MVVM : Mod√®le View View Model

DTO / Data
‚Üì
ServiceBack
‚Üì
InterfaceBack
‚Üì
ServiceUIFront
‚Üì
InterfaceUIFront
‚Üì
Front (Blazor)

L‚Äôarchitecture que tu d√©cris est une architecture en couches (layered architecture), avec une s√©paration stricte des responsabilit√©s entre la couche de donn√©es, les services backend, les interfaces de service, et la partie frontend (Blazor). Plus pr√©cis√©ment, cela s‚Äôapproche fortement d‚Äôun pattern DDD inspir√© (Domain-Driven Design) combin√© √† une architecture en oignon (Onion Architecture), adapt√©e √† un projet client/serveur (Blazor Server ou WebAssembly + API).

Voici ce que repr√©sente chaque couche :

üîπ 1. DTO / Data
Type : Mod√®le de transfert de donn√©es
Responsabilit√© : Transf√©rer les donn√©es entre couches sans logique m√©tier (ex: BatchDTOCreate)
Remarque : Utilis√© pour d√©coupler le mod√®le de domaine du frontend et pour la s√©rialisation/d√©s√©rialisation JSON
üîπ 2. ServiceBack
Type : Service m√©tier (couche Application)
Responsabilit√© : G√©rer la logique m√©tier c√¥t√© serveur (ex: cr√©er un lot, v√©rifier des contraintes)
Exemple : NewBatchService : INewBatchService
üîπ 3. InterfaceBack
Type : Interface d‚Äôabstraction pour les services backend
Responsabilit√© : Permet l‚Äôinjection de d√©pendances, facilite les tests et le d√©couplage
But : Permet de moquer les services dans les tests unitaires, respecter l‚Äôinversion de d√©pendance
üîπ 4. ServiceUIFront
Type : Service d‚Äôorchestration Blazor c√¥t√© client
Responsabilit√© : Appeler les services backend (via HttpClient), g√©rer l‚Äô√©tat UI local, effectuer de l‚Äôaggr√©gation
Exemple : NewBatchUIService : INewBatchUIService
üîπ 5. InterfaceUIFront
Type : Interface de service frontend
Responsabilit√© : M√™me principe que InterfaceBack, pour permettre l'injection dans les composants Blazor
But : Testabilit√©, lisibilit√©, s√©paration des pr√©occupations
üîπ 6. Front (Blazor)
Type : Composants UI (Razor)
Responsabilit√© : Affichage et interaction utilisateur, logique de pr√©sentation
Exemple : NewBatch.razor
üèóÔ∏è Type global d‚Äôarchitecture
Cela peut √™tre r√©sum√© comme :

Architecture en couches d√©coupl√©es avec interfaces, inspir√©e de Clean Architecture ou Onion Architecture, adapt√©e √† un front Blazor.

---

Concernant la partie mobile, des routes on √©t√© mises en place cot√© blazor pour permettre d'avoir acc√®s a la partie minimaliste de l'application. L'objectif de l'application mobile etant de pouvoir saisir et consulter rapidement les donn√©es des cuves, vendanges et autres.. Elle a √©t√© d√©velopp√©e avec Ionic, permettant une application cross-platform.

La base de donn√©es utilis√©e est PostgreSQL, avec une architecture orient√©e microservices pour faciliter l'√©volutivit√© et la maintenance.

[base de donn√©es diagram](GestionChais.png)

#### Acteurs internes/externes

J'ai pu g√©rer ce projet en tant que developpeur et product manager d'une equipe de 3. Nous avons r√©alis√© dans la mesure du possible avec nos alternance respective une gestion de projet SCRUM par des reunion matinal de scrum, la tenu d'un Jira ou j'ai pu r√©aliser les user story et les tickets en liens avec les figma et le designers de l'entreprise. Des testes de grooming par poker planning, puis finalement par identification par collaborateur. Nous avons √©galement mis en place dans un premier temps des reunion splus eparces puis rassembl√© les sprint plannings, sprint review et groming sur la meme demi journ√©e, permettant de terminer et lancer un sprint dans les meilleures conditions.
Celle ci etait lanc√© en milieu de semaine pour eviter la mise en production en fin de semaine.

Un clients r√©f√©rents √©tant pr√©sent lors de chacune des reunions, pour permettre la liaison entre les clients finaux potentiels et l'equipe de dev. Cela a permis d'avoir acc√®s a des cas m√©tiers.

En prenant du recul sur ce projet, la double casquette PM et developpeur a √©t√© une belle experience pour d√©couvrir les deux m√©tiers, voir meme prendre en compte le role de scrum master. Cependant la quantit√© de missions et la r√©gularit√© de chacune a √©t√© difficile a r√©aliser de mani√®re peirenne et des actions mises en place pouvait se perdre lors de moment de cours, ou simplement par les moments de charge de travail plus important.

Ainsi si cela avait √©t√© a refaire une augmentation de la rigueur de travail par une plannification des taches que j'ai pu maintenant connaitre en gestion de projet informatique permettrait un meilleur suivis des uses cases et du cas clients pouvant, comme dans chaque projet, etre changeant.

---

## II. Projet personnel

---

N'ayant pas eu la chance d'avancer assez vite par rapport a la road map fix√© en d√©but de projet et avec des changements de modules / architecturaux importants, je n'ai pas eu l'opportunit√© de r√©aliser les missions d'intelligence artificielle pr√©vues dans le cadre de mon alternance. Par ailleurs, j'ai pu travailler sur des projets personnels qui m'ont permis de d√©velopper mes comp√©tences en IA et Data Science.

Trois projets m'ont permit de developper des comp√©tences en intelligence artificiel. En partant de la consommation des API donn√©e par les grands groupes a la r√©alisation de l'entrainement d'une IA de pr√©diction.

Le premier est celui qui m'a donn√©e encore plus de ferveur d'apprendre a utiliser et faire fonctionner une intelligence artificelle.

### üß™ Projet 1 ‚Äì POC de mod√©ration d‚Äôimage via IA (ChatGPT + Vision) ‚Äì Cas GEEV

Celui ci a comenc√© lors d'une discussion a la fin de mon d√©but de reconversation lors d'une des non-conf√©rences organis√©es par l'associatiion bordelaise Okiwi.
Non-conf√©rences ou j'ai pu discuter avec Alexandre CTO de Geev, et echanger avec lui sur l'IA, j'ai √©t√© etonnament surpris de l'avis de quelques developpeurs sur leurs non utilisation (c'etait en 2024 donc moins embarqu√© encore qu'aujourd'hui) voir leurs r√©ticence. Et lui a √©t√© surpris de mes connaissance et mon envie d'apprendre.

Nous avons beaucoup √©chang√© lors de la conf√©rence. Puis ensuite echang√© pendant quelques semaines avant de d√©cider conjointement que je r√©aliserais un stage de deux mois chez eux pour me permettre d'apprendre et eux de tester differents uses cases.

Avec mon pass√© dans le commerce et en tant que manager. J'ai eu une double casquette.

La premi√®re de developper un poc pour deux sujets. Le premier la mise en place de test pour la discussions et prise de rendez vous automatis√© pour les personnes voulant donner un objet. Le deuxi√®me sur la mod√©rations par le biais des photos.

La deuxi√®me casquette √©tait sur des sujets plus humains comme la mise en place d'une phase de recherche sur l'utilisation de l'IA par les diff√©rents m√©tiers de l'entreprise et comment l'integrer dans leurs metiers. Mais √©galement sur la transmission de connaissance sur les normes RGPD et IA act.

Pour la r√©alisation du premier POC j'ai r√©alis√© rapidement une interface de discussion front, avant de passer pour plus de scalabilit√© a des testes avec l'aide de Jest, le back de test a √©t√© d√©velopp√© en node Typescript avec Langchain. Framework permettant le plug and play de diff√©rentes IA. En effet ce framework aujourd'hui beaucoup plus en vogue, √©tait utilis√© dans un premier temps en 2024 pour faire du chainage de prompt, permettre d'une certaine m√©moire.
J'ai ainsi pour d√©velopper un assistant d'IA qui utilisait quelque peut les principes des agents aujourd'hui. En effet a ce jours un agent permet de faire passer a des IA plus sp√©cifique ou a la memem IA mais avec des prompts sp√©cifiques, voir des IA ayant re√ßu des entrainements ou RAG sp√©cifique. Ainsi j'avais un agent qui r√©alisait une extraction a partir du texte et de l'historique de la discussion. En fonction de la demande de l'utilisateur l'objectif etait d'avoir un mot en r√©ponse sp√©cifique, ce mot permettait d'envoyer la discussion vers une autre IA qui allais elle r√©pondre ou chercher de l'information. Cela permettait d'eviter les fuite de m√©moire, les prompts trops long etc..

Le deuxi√®me est la mod√©ration par IA pour l'acceptation de cr√©ation d'annonce. Le besoin etait d'eviter a la personnes faisant la mod√©ration d'avoir a la r√©aliser a la main sur 45% des annonces mais plutot de r√©aliser cela sur les alerte lev√© par l'IA.
Le teste a √©t√© concluent, r√©alis√© √©galement avec Jest pour l'envoie de photo attendants une r√©ponse particuli√®re.
Pour ce poc un simple prompt de v√©rification selon les CGU permettait de faire en sorte de filtrer plus de 90% des photos qui n'aurait pas du se retrouver sur le site. Le mod√®le GPT vision etant le meilleur dans ce traitement car entrain√© a l'epoque sur une grande quantit√© de photo et video c'etait celui permettant l'absorption de la plus grande volum√©trie de requete, pour les autre IA tels que Gemmini, le chat ou Deepsek des timout etait attribu√© au bout de 10 requetes envoy√© en meme temps, et le retour n'etait pas de la meme qualit√© que GPT.

Sur cet exemple, avec le temps qu'il me restait sur le stage, nous avons fait le choix de tester la cr√©ation d'annonce a partir d'IA. Test concluent √©galement a 90%, en effet l'IA d'open AI n'etait pas capable a chaque iteration de reconnaitre par exemple une boucle de cheveux avec un chien. L'objectif ici etait de tester l'IA vision, comparer et v√©rifier les coup en production par rapport au nombre d'annonce produite par jours. Et la mani√®re de mon√©tiser cette fonctionalit√©. Finalement le projet, trop honnereux pour le moment a √©t√© abandonn√©e.

### ü§ñ Projet 2 ‚Äì Assistant IA mus√©al interactif (LangChain + GPT vision + TTS)

Suite √† ce projet o√π j'ai pu exp√©rimenter l'IA et la force du framework d'abstraction LangChain, j'ai r√©alis√© un voyage √† Paris de quelque jours, voyage durant lequel j'ai pris le temps de visiter le mus√©e du Louvre. Amateur d'art mais avec une connaissance tr√®s faible, j'ai pris le parti de faire un test avec ChatGPT dans leur application, en utilisant un prompt simple, quelques noms d'artistes, et l'envoi de photos d‚Äô≈ìuvres.

Ce test concluant m'a permis, gr√¢ce au pouvoir de l'entrainement massif de chat GPT 4 sur des millions de data et √† la richesse d‚ÄôInternet en mati√®re de contenu culturel, de prendre encore plus de plaisir dans ma visite. J‚Äôai pu personnaliser enti√®rement mon propre parcours de visite en choisissant les tableaux qui m‚Äôattiraient, en apprenant √† mon rythme, et m√™me en vivant une sorte de mini chasse au tr√©sor organis√©e par l‚ÄôIA : celle-ci me proposait de retrouver des ≈ìuvres √† partir de description qu‚Äôelle-m√™me me formulait.

√Ä la suite de cette exp√©rience, l‚Äôid√©e d‚Äôune application d√©di√©e a √©merg√©. J‚Äôai d‚Äôabord d√©velopp√© une premi√®re version backend pour tester le concept, puis mis en ≈ìuvre une premi√®re version fonctionnelle en √©quipe, encore en cours de d√©veloppement √† ce jour.

#### Architecture technique

J'ai ainsi pu d√©ployer une architecture technique moderne, modulaire et maintenable, pens√©e pour r√©pondre aux exigences d‚Äôun syst√®me embarquant de l‚Äôintelligence artificielle tout en restant fluide et accessible pour un large public.

J'ai dans un premier temps mont√© un conteneur docker contenant le back end. Celui ci avec une architecture hexagonale pour un syst√®me robuste et √©volutif.

Le socle applicatif a √©t√© con√ßu avec Node.js, le framework Express, et une surcouche permettant un d√©veloppement en TypeScript.

L‚Äôensemble est organis√© selon une architecture hexagonale, aussi appel√©e architecture en oignon.

![ref : https://www.linkedin.com/pulse/whats-hexagonal-architecture-luis-soares-m-sc-/](./hexagonalArchitecture.png)

Dans les explication de Luis Soares qui explique cette architecture suite a la cr√©ation de celle ci par Alistair Cockburn dans les ann√©es 2000. Cette ind√©pendance garantit une forte coh√©sion du code m√©tier et une facilit√© de test unitaire.
Selon Luis Soares, l‚Äôarchitecture hexagonale est un mod√®le d‚Äôarchitecture logicielle qui vise √† s√©parer la logique m√©tier de l‚Äôapplication des d√©tails techniques et des interactions avec le monde ext√©rieur. Elle repose sur les concepts de Ports et d‚ÄôAdaptateurs, permettant ainsi une flexibilit√© et une maintenabilit√© accrues.

Le mod√®le de domaine (Domain Model)

Coeur de l‚Äôarchitecture, il incarne la logique m√©tier principale de l‚Äôapplication. Regroupe les entit√©s, les r√®gles m√©tier et les comportements fondamentaux, ind√©pendamment de toute technologie ext√©rieure (base de donn√©es, interface utilisateur, r√©seau, etc.). Cette ind√©pendance garantit une forte coh√©sion du code m√©tier et une facilit√© de test unitaire.

Les Ports :

Ils d√©finissent les points de communication entre la logique m√©tier et le monde ext√©rieur. Il existe deux types de ports :

- Ports primaires : ce sont les interfaces que l‚Äôapplication expose vers l‚Äôext√©rieur. Ils traduisent les cas d‚Äôusage que les utilisateurs ou syst√®mes peuvent d√©clencher (par exemple via une API REST ou une interface mobile).
- Ports secondaires : ce sont les interfaces dont la logique m√©tier d√©pend pour interagir avec des services ext√©rieurs (bases de donn√©es, syst√®mes tiers, etc.). Ils d√©finissent ce que l‚Äôapplication attend d‚Äôun composant technique.

Les Adaptateurs

Les adaptateurs impl√©mentent concr√®tement les ports pour √©tablir la connexion entre la logique m√©tier et l‚Äôenvironnement technique. Eux aussi se divisent en deux cat√©gories :

- Adaptateurs primaires : ils traduisent les entr√©es provenant de l‚Äôext√©rieur (requ√™tes HTTP, actions utilisateur, etc.) en appels aux cas d‚Äôusage internes.
- Adaptateurs secondaires : ils fournissent l‚Äôimpl√©mentation des services attendus par les ports secondaires (acc√®s aux donn√©es, appel √† une API externe, etc.).

J'ai reproduit l'architecture hexagonale a partir de ce que j'avais appris par le biais de Geev dont voici un exemple concret de cette architecture dans le projet, appliqu√©e au module de traitement des images (imageInsight) :

![architecture de l'insight de l'image](./ArchitectureHexagonale.png)

La structure est ainsi divis√©e en deux grandes couches principales :

**Couche Core** qui est le coeur logique du m√©tier :
Elle regroupe les entit√©s m√©tier, les interfaces (ports) et les cas d‚Äôusage. Dans notre projet, cela correspond aux √©l√©ments suivants :

le dossier domain/ comprenant les fichiers suivants :

- imageInsight.entity.ts : repr√©sente une ≈ìuvre ou une analyse effectu√©e √† partir d‚Äôune image. Cette entit√© encapsule les r√®gles m√©tier comme la validation ou la g√©n√©ration d‚Äôidentifiants.
- imageInsightConversation.entity.ts : mod√©lise une session ou un √©change, souvent li√©e √† un utilisateur ou √† un parcours de visite. Sert √† l'ORM pour builder la base de donn√©es.
- imageInsightMessage.entity.ts : structure les messages √©chang√©s lors de l‚Äôanalyse, que ce soit une question, une r√©ponse IA ou une interaction interm√©diaire. Sert √† l'ORM pour builder la base de donn√©es.
- imageInsight.repository.interface.ts : interface d√©finissant les contrats d‚Äôacc√®s aux donn√©es pour la persistance. Ce port secondaire est inject√© dans les cas d‚Äôusage pour garantir l‚Äôind√©pendance vis-√†-vis de la technologie de stockage.

le dossier useCase/ comprenant les fichiers suivants :

- createImageInsight.useCase.ts : contient la logique applicative n√©cessaire √† la cr√©ation d‚Äôun insight (analyse d‚Äôimage). Il coordonne les appels entre les entit√©s, les services d‚Äôanalyse (ex : IA), et les persistances. Ce cas d‚Äôusage ne conna√Æt ni Express, ni PostgreSQL, ni TypeORM : il est 100 % ind√©pendant.
- index.ts : point d‚Äôentr√©e pour l‚Äôinjection des d√©pendances et l‚Äôagr√©gation des cas d‚Äôusage.

**Couche Adapters** qui est l‚Äôinterface avec le monde ext√©rieur

Cette couche adapte les appels ext√©rieurs (ou drivers comme vu au dessus) √† la logique m√©tier. Elle est divis√©e entre :

le dossier adapters/primary/http

- imageInsight.route.ts : cette route Express sert d‚Äôentr√©e HTTP. Elle re√ßoit les requ√™tes (comme l‚Äôupload d‚Äôimage), appelle les cas d‚Äôusage via le service appropri√©, puis retourne la r√©ponse au format JSON. Cette couche peut √™tre remplac√©e par une API GraphQL ou un CLI sans impacter la logique m√©tier. Elle contient √©galement les commentaire du swagger permettant de documenter l'API.

le dossier adapters/secondary/

- imageInsight.analyzer.ts : cet adaptateur secondaire joue le r√¥le de passerelle vers l‚ÄôIA. Il encapsule l‚Äôappel √† LangChain et donc OpenAI, permettant d‚Äôobtenir une analyse visuelle ou contextuelle d‚Äôune ≈ìuvre. Dans un premier temps c'est elle qui contient √©galement le prompt de base pour l'analyse de l'image.
- imageInsight.repository.pg.ts : impl√©mentation de l‚Äôinterface de persistance avec TypeORM et PostgreSQL. Ce fichier interagit directement avec la base, tout en respectant les interfaces d√©finies dans domain.

Le grand avantage de cette architecture est l‚Äôinversion des d√©pendances : ce sont les adaptateurs secondaires qui d√©pendent du c≈ìur m√©tier, jamais l‚Äôinverse. Concr√®tement, cela signifie que l‚Äôon peut remplacer une base PostgreSQL par une base MongoDB, ou une IA OpenAI par une IA locale, sans modifier les cas d‚Äôusage.

#### Int√©gration de l‚Äôintelligence artificielle avec LangChain et GPT-4 Vision

Comme vu au dessus l'application repose sur une architecture permettant d'etre scalable et modulaire. Mais l'utilisation du Framework Langchain, permet de faciliter la cr√©ation de cha√Ænes d‚Äôinteractions entre l‚Äôutilisateur et un mod√®le de langage (LLM). Il permet notamment de g√©rer la m√©moire conversationnelle, le cha√Ænage d‚Äôoutils, de prompt, l'ajout de texte param√©tr√©, la r√©partition des t√¢ches entre plusieurs modules IA, ou encore l‚Äôanalyse s√©mantique enrichie.

Les modules IA impl√©ment√©s incluent :

- Analyse d‚Äôimage : gr√¢ce √† GPT-4 Vision, les ≈ìuvres envoy√©es sont analys√©es. L‚ÄôIA peut identifier des √©l√©ments visuels, des styles, des √©motions, et m√™me proposer des liens avec d‚Äôautres ≈ìuvres ou artistes, car son prompt est enrichie et lui permet de comprendre le contexte culturel ainsi que la localisation de l'oeuvre.
- R√©ponses culturelles personnalis√©es : chaque interaction est enrichie avec des anecdotes, des r√©f√©rences historiques, ou des liens vers d‚Äôautres ≈ìuvres similaires, afin de cr√©er une exp√©rience de visite augment√©e.
- M√©moire de la discussion : L'application garde en m√©moire les ≈ìuvres d√©j√† explor√©es, les th√®mes abord√©s, ou les pr√©f√©rences exprim√©es, ce qui permet de construire d'int√©grer dans les prompt √† l'avenir toutes ses m√©triques et ainsi d'avoir un v√©ritable parcours d‚Äôexploration sur mesure pour chaque utilisateur.

üìå Capture d'√©cran du prompt et d'un test ?

‚∏ª

#### Base de donn√©es : persistance fiable avec PostgreSQL + TypeORM

Comme indiqu√© au dessus, les conversations, les messages, la gestion utilisateur sont stock√©es dans une base PostgreSQL, int√©gr√©e dans un conteneur Docker d√©di√©. Cette base contient :

- Les utilisateurs (authentification)
- Les conversations et messages

L‚Äôusage de TypeORM permet de maintenir un bon niveau d‚Äôabstraction vis-√†-vis du sch√©ma de la base, facilitant les migrations et les √©volutions du mod√®le de donn√©es sans rompre la logique applicative existante.

‚∏ª

#### Conteneurisation avec Docker : portabilit√© et d√©ploiement autonome

Pour garantir un d√©ploiement rapide, qu'importe le poste, toute l‚Äôarchitecture backend a √©t√© conteneuris√©e avec Docker, cela permet de :

- Isoler les composants : backend, base de donn√©es, services tiers
- Faciliter les tests et la mise en production
- D√©ployer rapidement sur tout type d‚Äôinfrastructure, sans d√©pendance forte √† un cloud sp√©cifique.

L‚Äôensemble du projet a √©t√© h√©berg√© sur un serveur VPS OVH, configur√© pour supporter les diff√©rentes charges applicatives, g√©rer les logs, et permettre des d√©ploiements it√©ratifs √† l‚Äôaide de docker-compose.

Le projet a ainsi 3 services principaux :

- le backend
- la base de donn√©es
- adminer permettant d'administrer la base de donn√©es

Tout √©tant partag√© par un volume de donn√©e permettant de garder les donn√©es persistantes entre les red√©marrages du conteneur.

üìå [Capture d'√©cran du docker compose et des diff√©rents services]

‚∏ª

#### Frontend mobile

Pour l‚Äôinterface utilisateur, nous avons opt√© pour React Native avec TypeScript, en utilisant le Framework Expo. L'objectif est de produire une application mobile cross-platform performante, tout en assurant une coh√©rence du design, une rapidit√© de developpement multi plateform gr√¢ce a React Native nous permet de r√©aliser un POC rapidement.

Les √©crans d√©j√† fonctionnels √† ce jour comprennent :

- Une page d‚Äôaccueil avec authentification
- Un tableau de bord centralisant les conversations pass√©es
- Une interface de chat, avec aper√ßu en direct des images d‚Äô≈ìuvres envoy√©es
- Une navigation th√©matique via des tags, permettant √† l‚Äôutilisateur d‚Äôexplorer dans un premier temps AJOUTER LES TAG POSSIBLE

Le tout est stylis√© avec Tailwind CSS, adapt√© √† React Native, pour assurer un rendu esth√©tique coh√©rent, moderne et surtout ergonomique sur mobile.

üìå [Capture sugg√©r√©e : aper√ßu de l‚Äô√©cran de chat avec un visuel d‚Äô≈ìuvre et une r√©ponse IA]

#### Vers une m√©diation culturelle augment√©e

Ce projet est n√© d‚Äôune simple exp√©rience personnelle et s‚Äôest mu√© en un v√©ritable assistant intelligent au service de la m√©diation culturelle. Il repose sur une approche d'utilisation de l‚Äôintelligence artificielle g√©n√©rative tels que chat GPT qui a engrang√© une quantit√© enorme d'inforamation et est donc capable de connaitre, reconnaitre et traiter un grand ensemble d'oeuvres permettant ainsi d'envisager la mise en place d'une section oeuvre inconnu avec par exemple des oeuvres afficaines qui ne sont pas ou pas connu et permettrait ainsi d'avoir acc√®s a une culture et de l'art meme dans une r√©gion ou celle ci est moins expliqu√© car ne pr√©sente pas de conservateur pour mettre ne place des parcours utilisateur et des explicaitons d'oeuvres.
Nous pouvons √©galement imaginer l'ajout de synth√®se vocale (TTS), l'int√©gration de parcours g√©olocalis√©s dans les mus√©es, ou encore enrichissement collaboratif des donn√©es culturelles.

Plus qu‚Äôun projet technique, c‚Äôest une exp√©rience sensible, un moyen de r√©enchanter la visite culturelle pour tous, √† son propre rythme, avec une technologie qui s‚Äôefface pour laisser place √† la d√©couverte.

### üß™ Projet 3 ‚Äì Plateforme pr√©dictive √©pid√©miologique (FastAPI + AutoGluon + Azure)

### 1. Contexte et enjeux du projet

#### 1.1 Contexte sanitaire et besoin de pr√©diction

Ce projet s‚Äôinscrit dans le cadre du module MSPR TPRE502, dans une logique de mise en ≈ìuvre compl√®te de la cha√Æne de valeur d‚Äôun projet IA‚ÄØ: depuis la collecte et la pr√©paration des donn√©es jusqu‚Äô√† la mise √† disposition d‚Äôun service pr√©dictif via une API. L'objectif principal de ce projet √©tait la cr√©ation d'un mod√®le permettant la pr√©diction de cas dans le cadre de l'√©pid√©mie de covid et la variole du Singe.

Pour cela nous avons mis en place un double objectif :

- **Construire une plateforme de pr√©diction multi-cibles √©pid√©miologiques**, capable de pr√©dire plusieurs indicateurs (nouveaux cas, d√©c√®s, r√©cup√©rations, etc.) en fonction de la g√©olocalisation et du temps.
- **D√©ployer une solution modulaire, conteneuris√©e et document√©e**, permettant une int√©gration rapide dans un syst√®me d‚Äôinformation de sant√© publique ou dans un outil de data visualisation.

#### 1.2 Positionnement dans la cha√Æne de valeur Data / IA

Ce projet se positionne sur l‚Äôensemble des √©tapes du cycle de vie d‚Äôun produit Data :

- **Collecte** : extraction des donn√©es en csv COVID et MPOX depuis des sources open Data
- **Pr√©paration** : nettoyage, enrichissement et structuration des donn√©es a partir d'excel pour v√©rifier globalement la mani√®re d'utiliser les donn√©es
- **Injestion** : injestion des donn√©es par l'utilisation de DBT et integration de toutes les donn√©es dans des tables postgresql
- **Transformation** : mod√©lisation s√©mantique avec DBT et structuration √©toile orient√©e analytique,
- **Entra√Ænement IA** : pr√©diction automatique avec AutoGluon en multi-cibles,
- **D√©ploiement** : exposition des pr√©dictions via une API REST document√©e avec FastAPI,
- **Exploitation** : visualisation via une interface frontend en React, avec int√©gration directe de l‚ÄôAPI.

Ce projet m‚Äôa permis de mobiliser √† la fois mes comp√©tences en traitement de donn√©es, en Machine Learning, en d√©veloppement backend et en architecture logicielle.

## 2. Architecture technique et choix technologiques

### 2.1 Vue d‚Äôensemble de l‚Äôarchitecture

L‚Äôarchitecture technique du projet a √©t√© pens√©e selon un mod√®le **modulaire, conteneuris√© et √©volutif**, reposant sur les grands principes du d√©veloppement moderne : s√©paration des responsabilit√©s, scalabilit√© et automatisation.

Elle s‚Äôarticule autour de 4 couches principales :

1. **Traitement et Ingestion des donn√©es** (ETL + mod√©lisation via DBT)
2. **Exposition des donn√©es** exposition des donn√©es avec metabase et d'une APi REST pour pouvoir ajouter ou modifier les donn√©es
3. **Machine Learning** (entra√Ænement automatique des mod√®les avec AutoGluon)
4. **Exposition des r√©sultats** (API FastAPI + interface utilisateur React)

L‚Äôensemble est orchestr√© via Docker, garantissant la reproductibilit√©, la compatibilit√© entre environnements, et la facilit√© de d√©ploiement. Des tests ont meme √©tait fait pour utiliser un orchestrateur en fonction des pays a partir de kubernetes.

## J'EN SUIS LA

### 3.3 Sch√©ma d‚Äôarchitecture

[Schema d l'architeture a a r√©cup√©rr du dossier word] ()

### 3.2 Choix des technologies

#### üß± Backend API ‚Äì FastAPI

- **Motivation** : Rapidit√© de d√©veloppement, support natif d‚ÄôOpenAPI, int√©gration facile avec Pydantic pour la validation des donn√©es.
- **Usage** : Exposition de routes REST pour la pr√©diction, la consultation des mod√®les disponibles et l‚Äôinsertion des r√©sultats en base PostgreSQL.

#### ü§ñ Machine Learning ‚Äì AutoGluon

- **Motivation** : Plateforme AutoML puissante, permettant l‚Äôautomatisation compl√®te de l‚Äôentra√Ænement de mod√®les.
- **Avantages** :

  - Support multi-mod√®les (LightGBM, CatBoost, FastAI, NeuralNetTorch, etc.),
  - Stacking automatique sur plusieurs niveaux,
  - Optimisation int√©gr√©e sur des m√©triques de r√©gression (RMSE, MAE, R¬≤),
  - D√©finition d‚Äôune limite de temps par cible (600 secondes) pour √©quilibrer performance et co√ªt.

- **R√©sultat** : Un mod√®le distinct par indicateur √©pid√©miologique, stock√© dans un r√©pertoire versionn√© (`/models/`), avec score par pays, ann√©e et continent.

#### üóÉÔ∏è Base de donn√©es ‚Äì PostgreSQL

- Stockage des donn√©es brutes et retrait√©es (mod√®le en √©toile avec table de faits et dimensions),
- Stockage des pr√©dictions effectu√©es par l‚ÄôAPI.

#### üîÑ DBT (Data Build Tool)

- **Motivation** : Structuration robuste des donn√©es en 3 couches :

  - **Bronze** : injection des donn√©es brutes COVID-19 et MPOX,
  - **Silver** : enrichissement g√©ographique et temporel,
  - **Gold** : table de faits pr√™te √† l‚Äôusage pour le Machine Learning.

- **Avantages** : documentation automatique, versionning des transformations, contr√¥le qualit√© int√©gr√©.

#### üíª Frontend ‚Äì React + Vite + Tailwind

- **Motivation** : Stack moderne, rapide √† mettre en place, r√©active et ergonomique.
- **Composants cl√©s** :

  - Formulaire d‚Äôentr√©e pour g√©n√©rer des pr√©dictions √† partir de donn√©es manuelles,
  - Affichage conditionnel des r√©sultats,
  - Ic√¥nes via Lucide React,
  - Graphiques via la librairie **Recharts**, permettant une int√©gration directe dans React sans surcharge inutile.

#### üê≥ Orchestration ‚Äì Docker & Docker Compose

- Conteneurisation des 4 services : `postgres`, `api`, `trainer`, `frontend`,
- R√©seau interne (`backend`, `frontend`) pour isolation,
- Montage du dossier partag√© `/models` pour que l‚ÄôAPI acc√®de aux mod√®les g√©n√©r√©s √† chaud par l‚Äôentra√Æneur.

## 4. M√©thodologie de travail et organisation

### 4.1 Approche projet

Ce projet a √©t√© men√© selon une approche **agile**, combinant planification initiale, it√©rations courtes, livraisons interm√©diaires et ajustements progressifs. Le but √©tait de favoriser la mont√©e en comp√©tence tout en produisant un livrable concret, utile et r√©utilisable.

Nous avons adopt√© les principes suivants :

- **D√©coupage modulaire** : chaque brique technique (ETL, ML, API, Frontend) a √©t√© d√©velopp√©e ind√©pendamment mais de mani√®re coh√©rente avec les autres.
- **Tests manuels fr√©quents** : notamment sur l‚ÄôAPI, les donn√©es d‚Äôentra√Ænement, les scores AutoGluon et les pr√©dictions finales.
- **Documentation progressive** : int√©gr√©e dans les scripts DBT, les readme de chaque dossier, et synth√©tis√©e dans le livrable final.

### 4.2 Organisation et outils

#### üõ†Ô∏è Outils utilis√©s

- **Trello** pour la gestion des t√¢ches et le suivi d‚Äôavancement,
- **Git** et **GitHub** pour le versionnement,
- **Docker Compose** pour la coh√©rence entre les environnements,
- **Notion** pour la documentation compl√©mentaire,
- **Metabase** pour la visualisation m√©tier en parall√®le du projet IA.

#### üìÜ Planification

Le projet a officiellement d√©but√© en **f√©vrier 2025** avec une premi√®re phase de cadrage fonctionnel et de prise en main des sources de donn√©es.

Un **diagramme de Gantt**, r√©alis√© via Instagantt, a permis de d√©finir les jalons suivants :

| √âtape principale                     | P√©riode approximative |
| ------------------------------------ | --------------------- |
| Analyse et cadrage                   | F√©v. 2025             |
| Mise en place du mod√®le de donn√©es   | Mars 2025             |
| D√©veloppement des mod√®les DBT        | Avril 2025            |
| Entra√Ænement des mod√®les IA          | Mai 2025              |
| D√©veloppement de l‚ÄôAPI & du Frontend | Juin 2025             |
| Finalisation, tests et rendu         | Juillet 2025          |

### 4.3 R√©partition des t√¢ches

Le projet a √©t√© con√ßu comme une d√©monstration compl√®te de mes comp√©tences en d√©veloppement IA & Data, avec une implication sur l‚Äôensemble des couches techniques :

- **Traitement de la donn√©e** (DBT, PostgreSQL) ‚Äì 30 %
- **Machine Learning** (AutoGluon, scripts Python) ‚Äì 40 %
- **API & Frontend** ‚Äì 20 %
- **Documentation & coordination projet** ‚Äì 10 %

Ce d√©coupage a permis une mont√©e en autonomie progressive, avec un rythme soutenu jusqu‚Äô√† la livraison finale.

5. R√©sultats obtenus et √©valuation
   5.1 Choix du framework : AutoGluon

Le projet n√©cessitait une solution d'apprentissage automatique capable de s'adapter √† plusieurs indicateurs cibles, sans multiplier la complexit√© algorithmique. AutoGluon a √©t√© retenu comme framework principal pour l‚Äôentra√Ænement des mod√®les en raison de ses atouts majeurs :

Automatisation du pipeline de machine learning : AutoGluon prend en charge l‚Äôingestion des donn√©es, le pr√©traitement, la s√©lection de mod√®les, la validation crois√©e, l‚Äôoptimisation d‚Äôhyperparam√®tres et l‚Äôassemblage final.
Stacking multi-niveaux : AutoGluon utilise une strat√©gie d‚Äôempilement (stacking) de mod√®les sur plusieurs couches (L1, L2‚Ä¶), permettant de combiner intelligemment plusieurs algorithmes comme LightGBM, CatBoost, XGBoost, NeuralNetTorch, KNN, etc.
Adaptabilit√© aux ressources : Un temps d‚Äôentra√Ænement maximal de 600 secondes a √©t√© impos√© pour chaque cible, assurant un bon √©quilibre entre performance pr√©dictive et co√ªt computationnel.
√âvaluation int√©gr√©e : Le framework permet un calcul direct de plusieurs m√©triques cl√©s : RMSE, MAE, R¬≤, et Pearson, facilitant la comparaison entre cibles.
5.2 Fonctionnement des mod√®les AutoGluon

Pour chaque indicateur cible (ex. : new_cases, new_deaths, active_cases, etc.), un mod√®le ind√©pendant est entra√Æn√© √† partir de donn√©es pr√©trait√©es (via DBT). Chaque mod√®le suit une proc√©dure stricte :

Pr√©paration du dataset :
Nettoyage des valeurs manquantes,
Ajout de features temporelles (jour, semaine, ann√©e),
Cr√©ation de moyennes mobiles sur 7 jours et deltas J-J7 pour capturer les tendances.
Split temporel :
70 % des donn√©es pour l'entra√Ænement,
15 % pour la validation,
15 % pour le test,
Une logique de fallback est int√©gr√©e si un des jeux est vide, en √©largissant dynamiquement l‚Äô√©chantillon.
S√©lection automatique de mod√®les de base :
AutoGluon essaie une centaine de configurations incluant : LightGBM (et LightGBMXT), CatBoost, XGBoost, KNN, Random Forest, Extra Trees, r√©seaux de neurones torch et FastAI.
Chaque mod√®le est entra√Æn√© et √©valu√© individuellement, puis les meilleurs sont combin√©s via un WeightedEnsemble_L2.
√âvaluation et scoring :
√Ä l‚Äôissue de l‚Äôentra√Ænement, chaque mod√®le est √©valu√© sur le jeu de test via les m√©triques pr√©cit√©es.
Les pr√©dictions sont sauvegard√©es et des scores par pays et par ann√©e sont √©galement produits sous forme de fichiers scores_by_group.csv.
Persistance des mod√®les :
Chaque mod√®le est sauvegard√© dans un dossier models/{target}/ accessible par l‚ÄôAPI FastAPI.
Une API d√©di√©e permet ensuite de charger dynamiquement le bon mod√®le et de produire des pr√©dictions en ligne √† partir de nouvelles donn√©es.
5.3 Interpr√©tation des r√©sultats

L'√©valuation des mod√®les a montr√© des performances contrast√©es selon les cibles. Les indicateurs de type new_cases ou new_deaths pr√©sentent une certaine stabilit√© gr√¢ce aux signaux temporels ajout√©s, tandis que new_recovered ou cases_per_million montrent davantage de variabilit√©, en lien avec les disparit√©s g√©ographiques et les biais de d√©claration.

Les scores n√©gatifs de R¬≤ observ√©s sur certaines cibles indiquent un fort d√©salignement entre les pr√©visions et les donn√©es r√©elles, ce qui a conduit √† des actions correctives : nettoyage plus strict, enrichissement de features, ou exclusion de cibles trop bruit√©es.

5.4 Bilan sur l‚ÄôIA et mes comp√©tences mobilis√©es

Ce projet m‚Äôa permis d‚Äôexplorer concr√®tement la mise en ≈ìuvre compl√®te d‚Äôun pipeline de machine learning en production :

Pr√©paration et ing√©nierie des features avanc√©e : int√©gration de signaux temporels, moyennes mobiles, cat√©gorisation g√©ographique.
Entra√Ænement multi-cibles automatis√© : gestion de mod√®les ind√©pendants, avec monitoring de la qualit√©.
Utilisation de mod√®les en ligne : int√©gration dans une API scalable et connect√©e √† une base PostgreSQL pour tracer les pr√©dictions.
√âvaluation fine : s√©lection de m√©triques pertinentes pour la r√©gression, et enregistrement structur√© des r√©sultats.
Capacit√© √† it√©rer rapidement pour corriger les erreurs (ex. : cibles trop bruit√©es, validation vide).
La robustesse d‚ÄôAutoGluon a √©t√© un levier important, mais c‚Äôest la ma√Ætrise de son param√©trage, de la gestion des donn√©es et de l‚Äôexploitation API qui ont permis d‚Äôen tirer le plein potentiel.
